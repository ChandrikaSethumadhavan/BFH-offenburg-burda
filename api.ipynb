{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "504186c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4381a118",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '': No scheme supplied. Perhaps you meant https://?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingSchema\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[288]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m header = {\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m:API_KEY}\n\u001b[32m      5\u001b[39m data = {\u001b[33m\"\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m incoming = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m incoming.status_code==\u001b[32m200\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(incoming.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\sessions.py:575\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[32m    563\u001b[39m req = Request(\n\u001b[32m    564\u001b[39m     method=method.upper(),\n\u001b[32m    565\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     hooks=hooks,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m prep = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m proxies = proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    579\u001b[39m settings = \u001b[38;5;28mself\u001b[39m.merge_environment_settings(\n\u001b[32m    580\u001b[39m     prep.url, proxies, stream, verify, cert\n\u001b[32m    581\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\sessions.py:484\u001b[39m, in \u001b[36mSession.prepare_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    481\u001b[39m     auth = get_netrc_auth(request.url)\n\u001b[32m    483\u001b[39m p = PreparedRequest()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\models.py:367\u001b[39m, in \u001b[36mPreparedRequest.prepare\u001b[39m\u001b[34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_method(method)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_headers(headers)\n\u001b[32m    369\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_cookies(cookies)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\requests\\models.py:438\u001b[39m, in \u001b[36mPreparedRequest.prepare_url\u001b[39m\u001b[34m(self, url, params)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(*e.args)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No scheme supplied. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No host supplied\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMissingSchema\u001b[39m: Invalid URL '': No scheme supplied. Perhaps you meant https://?"
     ]
    }
   ],
   "source": [
    "url = \"\"\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "header = {\"Authorization\":API_KEY}\n",
    "data = {\"item\":\"\"}\n",
    "incoming = requests.get(url,headers=header,data=data)\n",
    "if incoming.status_code==200:\n",
    "    print(incoming.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6131c",
   "metadata": {},
   "source": [
    "Translating text from German to English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bad51bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f9f4a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\bfh\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-de-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "6762033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    # Tokenize the input text\n",
    "    tokenized_text = tokenizer.prepare_seq2seq_batch([text], return_tensors='pt')\n",
    "    \n",
    "    # Perform the translation\n",
    "    translation = model.generate(**tokenized_text)\n",
    "    \n",
    "    # Decode the translated text\n",
    "    translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "29973348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single recipe: ['Marzipan', 'Weizenmehl (Type 405)', 'Trockenhefe', 'Zucker', 'Vanillezucker', 'gemahlenen Mandeln', 'Stollengewürz', 'pflanzliche Milch', 'vegane Butter (Zimmertemperatur)', 'Rosinen', 'Orangeat', 'Zitronat', 'Saft (oder Rum)', 'Etwas Mehl zum Arbeiten', 'Puderzucker', 'Vanillinzucker', 'gemahlene Mandeln', 'veganeButter (Zimmertemperatur)', 'EtwasMehl zum Arbeiten']\n",
      "Global: ['Marzipan', 'Weizenmehl (Type 405)', 'Trockenhefe', 'Zucker', 'Vanillezucker', 'gemahlenen Mandeln', 'Stollengewürz', 'pflanzliche Milch', 'vegane Butter (Zimmertemperatur)', 'Rosinen', 'Orangeat', 'Zitronat', 'Saft (oder Rum)', 'Etwas Mehl zum Arbeiten', 'Puderzucker', 'Vanillinzucker', 'gemahlene Mandeln', 'veganeButter (Zimmertemperatur)', 'EtwasMehl zum Arbeiten', 'Ei (Größe M)'] ... (743 total)\n",
      "Recipes found: ['Veganes Stollenkonfekt', 'Wickeltorte', 'Orangen-Dessert mit Joghurt']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Iterable\n",
    "\n",
    "# --- basic helpers ---\n",
    "def clean_spaces(s: str) -> str:\n",
    "    \"\"\"Collapse multiple spaces and trim.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def join_ingredient_parts(item: dict) -> str:\n",
    "    \"\"\"Build a readable ingredient string including prefix/suffix if available.\"\"\"\n",
    "    prefix = item.get(\"prefix\") or \"\"\n",
    "    name = (item.get(\"ingredient\") or {}).get(\"name\", \"\") or \"\"\n",
    "    suffix = item.get(\"suffix\") or \"\"\n",
    "    text = clean_spaces(f\"{prefix}{name}\")\n",
    "    if suffix:\n",
    "        text = clean_spaces(f\"{text} {suffix}\")\n",
    "    return text\n",
    "def join_quantity(item:dict):\n",
    "    quantity = item.get(\"quantity\") or \"\"\n",
    "    unit = (item.get(\"unit\") or {}).get(\"name\",\"\") or \"\"\n",
    "    text = clean_spaes(f\"{quantity}{unit}\")\n",
    "    return text\n",
    "\n",
    "def iter_ingredients(recipe: dict) -> Iterable[dict]:\n",
    "    \"\"\"Iterate through all ingredient items in a recipe.\"\"\"\n",
    "    for block in recipe.get(\"ingredientBlocks\", []):\n",
    "        for it in block.get(\"ingredients\", []):\n",
    "            yield it\n",
    "    # some recipes also have ingredients listed inside content sections\n",
    "    for section in recipe.get(\"content\", []):\n",
    "        for it in section.get(\"ingredients\", []) or []:\n",
    "            yield it\n",
    "\n",
    "def dedup_keep_order(items: List[str]) -> List[str]:\n",
    "    \"\"\"Remove duplicates but keep the original order.\"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for x in items:\n",
    "        key = x.lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            result.append(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- load the JSON file ---\n",
    "with open(\"einfachbacken_export_200_recipes_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "recipes: List[Dict[str, Any]] = data.get(\"data\", {}).get(\"recipeExport\", [])\n",
    "\n",
    "\n",
    "# --- single recipe ---\n",
    "def ingredients_for_recipe(recipes: List[dict], recipe_name: str, dedup: bool = True) -> List[str]:\n",
    "    recipe = next((r for r in recipes if r.get(\"name\") == recipe_name), None)\n",
    "    if not recipe:\n",
    "        return []\n",
    "    items = [join_ingredient_parts(it) for it in iter_ingredients(recipe)]\n",
    "    \n",
    "    return dedup_keep_order(items) if dedup else items\n",
    "# --- all recipes combined ---\n",
    "def ingredients_global(recipes: List[dict], dedup: bool = True) -> List[str]:\n",
    "    items = []\n",
    "    for r in recipes:\n",
    "        items.extend(join_ingredient_parts(it) for it in iter_ingredients(r))\n",
    "    return dedup_keep_order(items) if dedup else items\n",
    "\n",
    "\n",
    "# --- per-recipe dictionary ---\n",
    "def ingredients_per_recipe(recipes: List[dict], dedup: bool = True) -> Dict[str, List[str]]:\n",
    "    result = {}\n",
    "    for r in recipes:\n",
    "        items = [join_ingredient_parts(it) for it in iter_ingredients(r)]\n",
    "        result[r.get(\"name\", \"Unnamed\")] = dedup_keep_order(items) if dedup else items\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- example usage ---\n",
    "one_recipe = ingredients_for_recipe(recipes, \"Veganes Stollenkonfekt\")\n",
    "print(\"Single recipe:\", one_recipe)\n",
    "\n",
    "all_ingredients = ingredients_global(recipes)\n",
    "print(\"Global:\", all_ingredients[:20], f\"... ({len(all_ingredients)} total)\")\n",
    "\n",
    "by_recipe = ingredients_per_recipe(recipes)\n",
    "print(\"Recipes found:\", list(by_recipe.keys())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "97504852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Zwiebel': '600 g', 'etwas Butterschmalz (oder Sonnenblumenöl) zum Anbraten': '', 'gemischtes Gulaschfleisch': '600 g', 'Salz': '0.5 TL', 'Pfeffer': '0.5 TL', 'Zucker': '1 TL', 'Rotwein': '300 ml', 'Paprikapulver (edelsüß)': '2 TL', 'Paprikapulver (rosenscharf)': '1 TL', 'getrockneter Majoran': '1 TL', 'gemahlener Kümmel': '1 TL', 'Wasser': '1 Liter', 'Essig': '1 EL', 'Petersilie': '1 Bd.', 'etwas Butterschmalz (oder Sonnenblumenöl)': '', 'etwas Salz': ''}\n",
      "['Klassisches Gulasch', 'Smørrebrød', 'Gurken-Sushi', 'Pfannkuchen-Raclette', 'Steak au four', 'Spitzkohl aus dem Ofen', 'Pfirsich-Dessert ', 'Piccata Milanese', 'Würzfleisch', 'Tortellini in Schinken-Sahne-Soße']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any, Iterable\n",
    "\n",
    "# --- basic helpers (same as before, with the typo fixed) ---\n",
    "def clean_spaces(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "def join_ingredient_parts(item: dict) -> str:\n",
    "    prefix = item.get(\"prefix\") or \"\"\n",
    "    name = (item.get(\"ingredient\") or {}).get(\"name\", \"\") or \"\"\n",
    "    suffix = item.get(\"suffix\") or \"\"\n",
    "    text = clean_spaces(f\"{prefix} {name}\")\n",
    "    if suffix:\n",
    "        text = clean_spaces(f\"{text} {suffix}\")\n",
    "    return text\n",
    "\n",
    "def extract_quantity_unit(item: dict) -> str:\n",
    "    q = item.get(\"quantity\")\n",
    "    q_str = \"\" if q in (None, \"\") else str(q)\n",
    "    unit_obj = item.get(\"unit\") or {}\n",
    "    unit = unit_obj.get(\"name\") or unit_obj.get(\"short\") or unit_obj.get(\"abbreviation\") or \"\"\n",
    "    return clean_spaces(f\"{q_str} {unit}\")  # e.g. \"200 g\" or \"\" if none\n",
    "\n",
    "def join_quantity(item: dict) -> str:\n",
    "    return extract_quantity_unit(item)\n",
    "\n",
    "def iter_ingredients(recipe: dict) -> Iterable[dict]:\n",
    "    for block in recipe.get(\"ingredientBlocks\", []):\n",
    "        for it in block.get(\"ingredients\", []):\n",
    "            yield it\n",
    "    for section in recipe.get(\"content\", []) or []:\n",
    "        for it in section.get(\"ingredients\", []) or []:\n",
    "            yield it\n",
    "\n",
    "# --- load your JSON export (adjust filename as needed) ---\n",
    "with open(\"einfachkochen_export_800_recipes_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "recipes: List[Dict[str, Any]] = data.get(\"data\", {}).get(\"recipeExport\", [])\n",
    "\n",
    "# --- NEW: dict of {ingredient: quantity} for ONE recipe ---\n",
    "def ingredients_qty_dict_for_recipe(recipes: List[dict], recipe_name: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Returns: { \"Sugar\": \"200 g\", \"Milk\": \"100 ml\", \"Egg\": \"2\" , ... }\n",
    "    If an ingredient appears multiple times, the last one wins.\n",
    "    \"\"\"\n",
    "    recipe = next((r for r in recipes if r.get(\"name\") == recipe_name), None)\n",
    "    if not recipe:\n",
    "        return {}\n",
    "    out: Dict[str, str] = {}\n",
    "    for it in iter_ingredients(recipe):\n",
    "        ing = join_ingredient_parts(it)\n",
    "        qty = join_quantity(it)  # already \"number unit\" or \"\"\n",
    "        out[ing] = qty\n",
    "    return out\n",
    "\n",
    "# --- OPTIONAL: dict of recipe -> {ingredient: quantity} for ALL recipes ---\n",
    "def ingredients_qty_dicts_all(recipes: List[dict]) -> Dict[str, Dict[str, str]]:\n",
    "    out: Dict[str, Dict[str, str]] = {}\n",
    "    for r in recipes:\n",
    "        rname = r.get(\"name\", \"Unnamed\")\n",
    "        d: Dict[str, str] = {}\n",
    "        for it in iter_ingredients(r):\n",
    "            ing = join_ingredient_parts(it)\n",
    "            qty = join_quantity(it)\n",
    "            d[ing] = qty\n",
    "        out[rname] = d\n",
    "    return out\n",
    "\n",
    "# --- example usage ---\n",
    "one_recipe_map = ingredients_qty_dict_for_recipe(recipes, \"Klassisches Gulasch\")\n",
    "print(one_recipe_map)  # {'Mehl': '300 g', 'Zucker': '120 g', ...}\n",
    "\n",
    "all_recipes_map = ingredients_qty_dicts_all(recipes)\n",
    "print(list(all_recipes_map.keys())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "90d83b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_texts_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4e707e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src_texts in one_recipe_map.keys():\n",
    "    inputs = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "\n",
    "    # Decode and print result\n",
    "    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    # print(translated_texts[0])\n",
    "    translated_texts_all.append(translated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f20def1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_keys = list(one_recipe_map)  # preserves order of insertion\n",
    "new_keys = translated_texts_all  # same length as old_keys\n",
    "\n",
    "# 1) safest: build a new dict\n",
    "renamed = {new: one_recipe_map[old] for old, new in zip(old_keys, new_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b48e49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_recipe_map = renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6f69098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pck = 7  # adjust if you like\n",
    "TL_G = 5\n",
    "EL_G = 15\n",
    "def quantity_conversion(quantity: str):\n",
    "    s = quantity.strip().lower()\n",
    "    # grab the first number (works for \"100 g\", \"100g\", \"1.5 kg\", \"250ml\")\n",
    "    m = re.search(r'([\\d.,]+)', s)\n",
    "    if not m:\n",
    "        return None\n",
    "    n = float(m.group(1).replace(',', '.'))  # <- n is just the number part\n",
    "\n",
    "    # convert to kg (simple assumptions)\n",
    "    if 'kg' in s:\n",
    "        convert = n\n",
    "    elif 'g' in s:\n",
    "        convert = n / 1000.0\n",
    "    elif 'ml' in s:\n",
    "        convert = n / 1000.0   # assume 1 ml ~ 1 g ~ 0.001 kg\n",
    "    elif 'l' in s:\n",
    "        convert = n \n",
    "    elif \" tl\" in s or s.endswith(\"tl\"):\n",
    "        convert = (n * TL_G) / 1000.0\n",
    "    elif \" el\" in s or s.endswith(\"el\"):\n",
    "        convert = (n * EL_G) / 1000.0\n",
    "    elif \" pck\" in s:\n",
    "        convert = (n * pck) / 1000.0           # assume 1 L ~ 1 kg\n",
    "    else:\n",
    "        convert = n * 0.1         # unknown unit\n",
    "\n",
    "    return convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "77ae35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e3cf381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\muthu\\Documents\\bfh\\BFH-offenburg-burda\\final_co2_emissions_only_germany.csv\",encoding=\"cp1252\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4145603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Emissions (CO2 eq/kg)':'Emissions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "230d1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    if isinstance(word,str):\n",
    "\n",
    "        word = word.lower()\n",
    "        word = word.split(\",\",1)[0]\n",
    "        \n",
    "    else:\n",
    "        word = \"\"\n",
    "    return word\n",
    "\n",
    "df[\"norm\"] = df[\"Product\"].map(normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e545b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "686a8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "name_vecs = model.encode(df[\"norm\"].tolist(), normalize_embeddings=True).astype(\"float32\")\n",
    "index = faiss.IndexFlatIP(name_vecs.shape[1])   # inner product == cosine for normalized vectors\n",
    "index.add(name_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "57928ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_lookup(name: str, addition, cos_cutoff=0.50):\n",
    "    q = model.encode([normalize(name)], normalize_embeddings=True).astype(\"float32\")\n",
    "    D, I = index.search(q, 1)  # top-1\n",
    "    sim = float(D[0][0])\n",
    "    if sim < cos_cutoff:\n",
    "        return None, 0.0, addition  # no match → 0 CO₂\n",
    "\n",
    "    idx = int(I[0][0])\n",
    "    row = df.iloc[idx]\n",
    "    kg_co2 = float(row[\"Emissions\"])\n",
    "\n",
    "    q_co2 = quantity_conversion(one_recipe_map[name])\n",
    "    if q_co2 is None:\n",
    "        return None, 0.0, addition  # missing quantity → 0 CO₂\n",
    "\n",
    "    total = kg_co2 * q_co2\n",
    "    addition += total\n",
    "\n",
    "    return row[\"norm\"], total, addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9fec2401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onion 0.15 0.15\n",
      "a little butter malt (or sunflower oil) to fry 0 0.15\n",
      "minced meat (beef \n",
      "and pork) 3.3539999999999996 3.5039999999999996\n",
      "salt 0.25 3.7539999999999996\n",
      "pepper 0.32 4.074\n",
      "sugar 0.6 4.6739999999999995\n",
      "red wine 0.432 5.106\n",
      "sweet pepper 1.28 6.386\n",
      "pepper 0.64 7.026\n",
      "marjoram 0.9 7.926\n",
      "Ground caraway 0 7.926\n",
      "mineral water 0.2 8.126\n",
      "vinegar 0.46 8.586\n",
      "parsley 0.04000000000000001 8.626\n",
      "a little butter malt (or sunflower oil) 0 8.626\n",
      "a little salt 0 8.626\n"
     ]
    }
   ],
   "source": [
    "addition = 0\n",
    "for i in list(one_recipe_map):\n",
    "    \n",
    "    p,t,a = embedding_lookup(i,addition=addition)\n",
    "    addition = a\n",
    "    if p is None:\n",
    "        p = i\n",
    "        t = 0\n",
    "    print(p,t,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "cfb23856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "42b2c198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marzipan',\n",
       " 'Wheat flour (type 405)',\n",
       " 'Dry yeast',\n",
       " 'Sugar',\n",
       " 'Vanilla sugar',\n",
       " 'Ground almonds',\n",
       " 'Stollen seasoning',\n",
       " 'vegetable milk',\n",
       " 'vegan butter (room temperature)',\n",
       " 'Rice',\n",
       " 'Orangeate',\n",
       " 'Citronate',\n",
       " 'Juice (or rum)',\n",
       " 'Some flour to work with',\n",
       " 'Powder sugar',\n",
       " 'Vanillin sugar',\n",
       " 'Ground almonds',\n",
       " 'vegan butter (room temperature)',\n",
       " 'Something to work with']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_texts_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502348c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
